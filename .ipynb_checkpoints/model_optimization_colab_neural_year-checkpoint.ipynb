{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c753c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'mongodb+srv://bluelilly2812lr:a1c3l12@lillyruetho.trsirdh.mongodb.net/'\n",
    "mongo = MongoClient(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47982b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that our new database was created\n",
    "print(mongo.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3422b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the database\n",
    "db = mongo['basketball_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the collections in our database\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_stats = db['basketball_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda74ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "team_stats_final_df = pd.DataFrame(bball_stats.find())\n",
    "\n",
    "# Review the DataFrame\n",
    "team_stats_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c51d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "# Separate the y variable, the outcome variable (wins)\n",
    "y = team_stats_final_df['wins_tot']\n",
    "# Separate the X variable, the features\n",
    "X = team_stats_final_df[['Year', 'pts_per_min', '2ft_pct', '3fg_pct', 'ts_pct', 'dbpm_tot', 'obpm_tot']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f030d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\", input_dim=7))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e833ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras hyper tuner to fine-tune the model\n",
    "# First import keras tuner\n",
    "!pip install keras_tuner\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6716985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=20,\n",
    "        step=2), activation=activation, input_dim=7))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=20,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on the test data using the optimized model\n",
    "predict_wins = best_model.predict(X_test_scaled)\n",
    "predictions_df = pd.DataFrame({'Actual Wins': y_test, 'Predicted Wins': predict_wins.flatten()})\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0aae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions_df['Actual Wins'], predictions_df['Predicted Wins'])\n",
    "plt.plot([predictions_df['Actual Wins'].min(), predictions_df['Actual Wins'].max()],\n",
    "         [predictions_df['Actual Wins'].min(), predictions_df['Actual Wins'].max()],\n",
    "         linestyle='--', color='red')\n",
    "plt.xlabel('Actual Wins')\n",
    "plt.ylabel('Predicted Wins Using Year')\n",
    "plt.title('Actual Wins vs Predicted Wins Using Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109af5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
